from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.sql.functions import *

if __name__ == "__main__":
    spark=SparkSession.builder.master("local[*]")\
        .config("spark.streaming.stopGracefullyOnShutdown","true")\
        .config("spark.sql.shuffle.partitions", 2) \
        .config("spark.sql.streaming.schemaInference","true") \
        .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0") \
        .getOrCreate()
        
    kafka_df=spark.readStream.format("kafka").option("kafka.bootstrap.servers","localhost:9092").option("subscribe","invoices1") \
        .option("startingOffsets","earliest").load()
        
    
    
    myschema=StructType([StructField("agent_id",StringType()),StructField("name",StringType()),StructField("sal",IntegerType()),
    StructField("desig",ArrayType(StringType())),StructField("address",StructType([StructField("dno",IntegerType()),
    StructField("street",StringType()),StructField("area",StringType()),StructField("city",StringType()),StructField("pin",IntegerType())])),
    StructField("other_info",StructType([StructField("Marital Status",StringType()),StructField("Education",StringType()),StructField("Language",StringType())]))])
    
    kafka_df.printSchema()
    
    value_df=kafka_df.select(from_json(col("value").cast("String"),myschema).alias("value"))
    
    flatten_df=value_df.select("value.*")
    
    
    clean_df=flatten_df.selectExpr("agent_id","name","sal","explode(desig) as designation","address.city as city","address.pin as pin","other_info.Language as Language","other_info.Education as education",
                          "case when sal>=100000 then 'High grade' when sal>=50000 then 'Medium grade' else 'Low grade' end as grade_level")
    
    
    df_out = clean_df.select(expr("agent_id as key"),to_json(struct("*")).alias("value"))
    
    kafka_write=df_out.writeStream.format("kafka").option("kafka.bootstrap.servers","localhost:9092").outputMode("update").triger("processingTime=330 seconds") \
                .option("topic","invoiceout").option("checkpointLocation","/home/hduser/checkpoint_kafka").start()
            
    kafka_write.awaitTermination()
